{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "30331f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "tv = TfidfVectorizer(ngram_range=(3,3), analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d98d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "99df1f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "6bb8c5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "6619f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "358a5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessing(data: pd.DataFrame):\n",
    "    \n",
    "    '''Returns X and y'''\n",
    "    \n",
    "    X = data['Text']\n",
    "    y = data[\"Language\"]\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(y)\n",
    "    \n",
    "    with open('Label_Encoder_ENG', 'wb') as files:\n",
    "        pickle.dump(le, files)\n",
    "    \n",
    "    data_list = []\n",
    "    \n",
    "    for text in X:\n",
    "        text = re.sub(r'[!@#$()~={}-<>/&*_\\'\"%,\\^*.?:;~`0-9]', ' ', str(text))\n",
    "        text = re.sub(r'[+-]', ' ', str(text))\n",
    "        text = re.sub(r'[[]]', ' ', str(text))\n",
    "        text = re.sub(r' +', ' ', str(text))\n",
    "        text = text.lower()\n",
    "        text = text.strip()\n",
    "        data_list.append(text)\n",
    "    data_list = pd.Series(data_list)   \n",
    "    \n",
    "    def removeNumeric(text):\n",
    "        return ' '.join([token for token in text.split() if token.isalpha()])\n",
    "    data_list = data_list.apply(lambda text: removeNumeric(text))\n",
    "    \n",
    "    return data_list, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "39059570",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = preProcessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c2f75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('--- Preprocessing is done! ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f5315be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 10000, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "540fe43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partialFit_predict(X, y, n_batches: int, laplace_smoothing_param: float):\n",
    "    \n",
    "    print('--- Partial training has begun! ---\\n')\n",
    "    '''Dividing the dataset into chunks before fitting'''\n",
    "    \n",
    "    def batches(l, n):\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i+n]\n",
    "            \n",
    "    x_shape = int(X.shape[0])\n",
    "    print(f'''Train Data shape: {x_shape}''')\n",
    "    global tv\n",
    "    i = 0\n",
    "    for batch in batches(range(len(X)), n_batches):\n",
    "        i+=1\n",
    "        model = MultinomialNB(alpha=laplace_smoothing_param)  # 0 means if a given trigram is not present, then apply no smoothing\n",
    "        print(f'''Dataset chunk number: {i}\\n''') \n",
    "        x_shape-=n_batches\n",
    "        print(f'''Train Data shape: {x_shape}\\n''')\n",
    "        try:\n",
    "            x = tv.fit_transform(X[batch[0]:batch[-1]+1]).toarray()\n",
    "            model.partial_fit(x, y[batch[0]:batch[-1]+1], classes=np.unique(y))\n",
    "        except:\n",
    "            x = tv.transform(X[batch[0]:batch[-1]+1]).toarray()\n",
    "            model.partial_fit(x, y[batch[0]:batch[-1]+1], classes=np.unique(y))\n",
    "\n",
    "    print('--- Training is done! ---\\n\\n')\n",
    "#     global y_test, x_test\n",
    "#     x_test = tv.transform(x_test).toarray()\n",
    "    \n",
    "    with open('tfidf_vectorizer_ENG', 'wb') as f:\n",
    "        pickle.dump(tv, f)\n",
    "    \n",
    "    with open('NB_Model_ENG', 'wb') as files:\n",
    "        pickle.dump(model, files)\n",
    "    \n",
    "#     y_pred = model.predict(x_test)\n",
    "#     ac = accuracy_score(y_test, y_pred)\n",
    "#     cr = classification_report(y_test, y_pred)\n",
    "#     print(f'''Accuracy score: {ac}\\n\\n''', cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c0eb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "partialFit_predict(x_train, y_train, 10000, laplace_smoothing_param=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07155ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
