{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f65aaa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from datatable import fread\n",
    "# import datatable as dt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11dd32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = open('eng_vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebb74db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = [word.replace('\\n', '') for word in vocab.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d4e1007",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05781535",
   "metadata": {},
   "source": [
    "## Removing English tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2b6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a71892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunct(data: pd.DataFrame):\n",
    "    data_list = []\n",
    "    y = data['Language']\n",
    "    for text in data['Text']:\n",
    "        text = re.sub(r'[!@#$(),n\"%^*.?:;~`0-9]', ' ', text)\n",
    "        text = re.sub(r'[[]]', ' ', text)\n",
    "        text = re.sub(' +', ' ', text).strip()\n",
    "        text = text.lower()\n",
    "        data_list.append(text)\n",
    "    \n",
    "    df = pd.Series(data_list, name='Text')\n",
    "    df = pd.concat([df, y], axis=1, names=['Text', 'Language'], ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "51a5beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_eng_texts(data: pd.DataFrame):\n",
    "    global vocab_list\n",
    "    df = removePunct(data)\n",
    "    for index, text in enumerate(df['Text'].values):\n",
    "        print(index)\n",
    "        eng_words = []\n",
    "        for token in text.lower().split():\n",
    "            if token in vocab_list:\n",
    "                eng_words.append(token)\n",
    "        if len(eng_words)!=0:\n",
    "            df = df.loc[~index]\n",
    "    \n",
    "    return df             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6af61261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indian_with_eng = [file for file in glob('*.csv')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f83cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = delete_eng_texts(df) #call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all-data-no-english.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29308c5",
   "metadata": {},
   "source": [
    "## Generate records with spelling mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d15d70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('dialects.csv')\n",
    "# df_guj = pd.read_csv('gujarati_clean.csv', usecols=['sentence'])\n",
    "# df_kan = pd.read_csv('kannada_clean.csv', usecols=['sentence'])\n",
    "# df_mar = pd.read_csv('marathi_clean.csv', usecols=['sentence'])\n",
    "# df_pun = pd.read_csv('punjabi_clean.csv', usecols=['sentence'])\n",
    "# df_urdu = pd.read_csv('urdu_clean.csv', usecols=['sentence'])\n",
    "# df_mal = pd.read_csv('malayalam_clean.csv', usecols=['sentence'])\n",
    "# df_hin = pd.read_csv('hindi_clean.csv', usecols=['sentence'])\n",
    "# df_ori = pd.read_csv('oriya_clean.csv', usecols=['sentence'])\n",
    "# df_tel = pd.read_csv('telugu_clean.csv', usecols=['sentence'])\n",
    "# df_tam = pd.read_csv('tamil_clean.csv', usecols=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe020e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ben['language'] = 'Bengali'\n",
    "# df_guj['language'] = 'Gujarati'\n",
    "# df_kan['language'] = 'Kannada'\n",
    "# df_mar['language'] = 'Marathi'\n",
    "# df_pun['language'] = 'Punjabi'\n",
    "# df_urdu['language'] = 'Urdu'\n",
    "# df_mal['language'] = 'Malayalam'\n",
    "# df_hin['language'] = 'Hindi'\n",
    "# df_ori['language'] = 'Oriya'\n",
    "# df_tel['language'] = 'Telugu'\n",
    "# df_tam['language'] = 'Tamil'\n",
    "# print('language column is created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e15d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('wrong_dialects.csv', 'a') as wrongs:\n",
    "#     for val in df['Text'].values:\n",
    "#         val = re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', val.lower()))\n",
    "#         wrongs.write(f'{val}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0e4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Text'] = df['Text'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('wrong_bengali.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f386fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ben_spell['sentence'] = df_ben['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# print('bengali generated')\n",
    "# df_guj_spell['sentence'] = df_guj['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# print('gujarati generated')\n",
    "# df_kan_spell['sentence'] = df_kan['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# print('kannada generated')\n",
    "# df_mar_spell['sentence'] = df_mar['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# print('marathi generated')\n",
    "# df_pun_spell['sentence'] = df_pun['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# print('punjabi generated')\n",
    "# #df_urdu_spell['sentence'] = df_urdu['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# df_mal_spell['sentence'] = df_mal['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# df_hin_spell['sentence'] = df_hin['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# df_ori_spell['sentence'] = df_ori['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# df_tel_spell['sentence'] = df_tel['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))\n",
    "# df_tam_spell['sentence'] = df_tam['sentence'].apply(lambda text: re.sub(r'(.)\\1+', r'\\1', re.sub(r'(.)\\1{2,}', r'\\1', text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e57717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ben_spell['language'] = 'Bengali'\n",
    "# df_guj_spell['language'] = 'Gujarati'\n",
    "# df_kan_spell['language'] = 'Kannada'\n",
    "# df_mar_spell['language'] = 'Marathi'\n",
    "# df_pun_spell['language'] = 'Punjabi'\n",
    "# #df_urdu_spell['language'] = 'Urdu'\n",
    "# df_mal_spell['language'] = 'Malayalam'\n",
    "# df_hin_spell['language'] = 'Hindi'\n",
    "# df_ori_spell['language'] = 'Oriya'\n",
    "# df_tel_spell['language'] = 'Telugu'\n",
    "# df_tam_spell['language'] = 'Tamil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = pd.concat([df_ben_spell, df_ben, df_guj, df_guj_spell, df_kan, df_kan_spell, \n",
    "#           df_mar, df_mar_spell, df_pun, df_pun_spell, df_mal, df_mal_spell,\n",
    "#           df_hin, df_hin_spell, df_ori, df_ori_spell, df_tel, df_tel_spell,\n",
    "#                      df_tam, df_tam_spell, df_urdu], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a8ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51327695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'''Duplicate records: {df_data.duplicated().sum()}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ccec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_data.sample(6))\n",
    "# print(df_data.tail(6))\n",
    "# print(df_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b83692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eng = pd.read_csv('english-data-clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7228c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data.to_csv('training-data.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle rarewords in english dataset\n",
    "#think about imbalance of urdu mainly\n",
    "#solve portuguese texts problem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
